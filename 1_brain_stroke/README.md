![dataset-cover](https://user-images.githubusercontent.com/103372805/207451838-b9764e29-2b42-4d4a-9994-aceba50767c7.jpg)

# Stroke Prediction

![tmp2943g1tv](https://user-images.githubusercontent.com/103372805/202800560-5b020e5d-5e22-4ea9-a05e-e40ca3fc2aa0.svg)

## 1. Описание
В данной работе нам необходимо предсказать у пациента инсульт, опираясь на 11 признаков. Данные взяты с сайта [Kaggle](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)

## 2. Что нужно сделать
Необходимо научиться как можно точней предсказывать инсульт у пациента, а также интерпретировать полученные результаты с помощью значений Шепли

## 3. Краткая информация о данных
1) **id**: *уникальный идентификатор*
2) **gender**: *пол пациента*
3) **age**: *возраст пациента*
4) **hypertension**: *наличие гипертензии у пациента*
5) **heart_disease**: *наличие сердечных заболеваний у пациента*
6) **ever_married**: *семейное положение*
7) **work_type**: *вид работы*
8) **Residence_type**: *место жительства*
9) **avg_glucose_level**: *средний уровень глюкозы в крови*
10) **bmi**: *индекс массы тела*
11) **smoking_status**: *статус курения*
12) **stroke**: *наличие инсульта у пациента*

## 4. Содержание работы
**_Разведочный анализ_**

В целом датасет оказался небольшим. Пропущенных данных было совсем немного (только у **bmi**). Также для данного датасета характерен сильный дисбаланс целевого класса
(положительные метки составляют чуть меньше 5 % от общего количества), что было учтено при моделировании. В ходе исследования были выявлены выбросы, но в итоге они не удалялись.
В ходе разведочного анализа были установлены зависимости между целевой переменной (наличие инсульта) и некоторыми признаками. Так, например, наибольшее влияние оказали 
возраст пациента, средний уровень глюкозы в крови и индекс массы тела (далее - ИМТ). Причём влияние ИМТ оказалось неоднозначным. 

**_Моделирование_**

Сравнение моделей проводилось с использованием библиотеки _scikit-learn_. Использовалась линейная модель (_LogisticRegression_), метод опорных векторов (_SVC_), модель на основе деревьев (_DecisionTreeClassifier_, _RandomForestClassifier_), а также бустинги (_XGBClassifier_, _LGBMClassifier_). Тюнинг гиперпараметров не проводился. Лучший результат показали алгоритмы на основе деревьев и бустинга. 

**_Интерпретация_**

С помощью значений [Шепли](https://shap-lrjball.readthedocs.io/en/latest/index.html) попытался интерпретировать полученные результаты на примере _XGBClassifier_

## 5. Результаты работы

Удалось добиться 100-процентной точности предсказания на тестовой выборке. Данный результат дали модели _DecisionTreeClassifier_, _RandomForestClassifier_, _XGBClassifier_ и _LGBMClassifier_.


